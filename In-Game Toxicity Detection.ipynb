{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCrCzhqoysCP"
      },
      "source": [
        "# Data And Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLi4x7XSysOa"
      },
      "source": [
        "## Data Download and Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE_R8hCDzEzM"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "drive = None\n",
        "def authenticate():\n",
        "    global drive\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "#Download files\n",
        "def downloadFiles(fileIds):\n",
        "    authenticate()\n",
        "    for fileId in fileIds:\n",
        "        downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
        "        downloaded.GetContentFile(fileId[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flVlngEM0nTU"
      },
      "outputs": [],
      "source": [
        "#Download file if not existing\n",
        "try:\n",
        "  _ = open(\"train.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"train.csv\", \"1pRTJ3aTh1yZV2ZN7Fof2NSt1c137SzYw\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"val.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"val.csv\", \"1khO0wHBC8bBzLVH4G09NhKTHHfAwBIna\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"test.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"test.csv\", \"1-E3dhTaMhG5oRKS9HGF9ZTTzsOKc_D14\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"dota.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"dota.csv\", \"1DCsO0uICmtabGiy8MQAYPl0xeDwhFP5S\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqJx_PJo2IFX",
        "outputId": "0748dfa4-64c4-4733-d913-d08856a7caa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26078\n",
            "<class 'list'>\n",
            "['wpe', 'wpe']\n",
            "['O', 'O']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(file_name, test=False):\n",
        "    f = pd.read_csv(file_name)\n",
        "\n",
        "    temp1 = f['sents'].tolist()\n",
        "    input_data = [sent.lower().split() for sent in temp1]\n",
        "\n",
        "    if not test:\n",
        "      temp2 = f['labels'].tolist()\n",
        "      target_data = [sent.split() for sent in temp2]\n",
        "\n",
        "      return input_data, target_data\n",
        "\n",
        "    return input_data\n",
        "\n",
        "train_data, target_y_train = read_data('train.csv')\n",
        "validation_data, target_y_validation = read_data('val.csv')\n",
        "test_data = read_data('test.csv', True)\n",
        "\n",
        "print(len(train_data))\n",
        "print(type(train_data[2]))\n",
        "print(train_data[2])\n",
        "print(target_y_train[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESpDFNNFysQw"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR63d4tY9LjD"
      },
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLhNETrW84qH"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRIpWbEV9GdR"
      },
      "source": [
        "### convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFIsMdcx9DA2"
      },
      "outputs": [],
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)\n",
        "# For kaggle leaderboard\n",
        "train_val_input_index = train_input_index + val_input_index\n",
        "train_val_output_index = train_output_index + val_output_index\n",
        "# test_output_index = to_index(target_y_test,tag_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vqpnyu9ysTB"
      },
      "source": [
        "## Input Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZhIz4lIzoHS"
      },
      "source": [
        "### Aspect 1) Syntactic Textual Feature Embedding: PoS tag information, Dependency Path, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrEM6FYn0iDa",
        "outputId": "8f229586-0f13-4149-e2e6-7d225c3bb972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "labels = [nlp(word)[0].tag_ for word in word_list]\n",
        "\n",
        "# one-hot encoding\n",
        "syntactic_labels = dict()\n",
        "for idx,label in enumerate(set(labels)):\n",
        "  syntactic_labels[label] = [0]*len(set(labels))\n",
        "  syntactic_labels[label][idx] = 1\n",
        "\n",
        "syntactic_embedding_dim = len(set(labels))\n",
        "\n",
        "syntactic_embedding_matrix = []\n",
        "for label in labels:\n",
        "    try:\n",
        "        syntactic_embedding_matrix.append(syntactic_labels[label])\n",
        "    except:\n",
        "        syntactic_embedding_matrix.append([0]*len(set(labels)))\n",
        "syntactic_embedding_matrix = np.array(syntactic_embedding_matrix)\n",
        "syntactic_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdwAZgqzp8v"
      },
      "source": [
        "### Aspect 2) Semantic Textual Feature Embedding: Word Embeddings (Word2Vec, ELMO, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wkMU2G40lMz",
        "outputId": "e803affb-4b90-4783-a984-bafa45bbbf42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "\n",
        "word_emb_model = api.load(\"glove-twitter-200\")\n",
        "\n",
        "semantic_embedding_dim = 200\n",
        "\n",
        "semantic_embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        semantic_embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        semantic_embedding_matrix.append([0]*semantic_embedding_dim)\n",
        "semantic_embedding_matrix = np.array(semantic_embedding_matrix)\n",
        "semantic_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6zil3Vaz4oS"
      },
      "source": [
        "### Aspect 3) Domain Feature Embedding: Your own new feature embedding to solve this in-game chat word slot filling(tagging)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGAFV9lRqiY9",
        "outputId": "6ec73a86-cc63-4a85-f5a0-263657eca5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "dota = pd.read_csv('dota.csv').dropna(subset=['key'])\n",
        "corpus = dota['key'].tolist()\n",
        "\n",
        "# Import libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Prepare training corpus for Gensim Word2Vec Skip-Gram model - List of List\n",
        "sentences=[]\n",
        "sentences=[word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "\n",
        "# Train the Gensim Word2Vec Skip-Gram model\n",
        "# domain_model = Word2Vec(sentences=sentences, size=50, window=2, min_count=1, workers=2, sg=1)\n",
        "domain_model = FastText(sentences=sentences, size=100, window=2, min_count=1, workers=2, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArDE49K0t4Ng"
      },
      "outputs": [],
      "source": [
        "# Save and load model\n",
        "domain_model.save(\"domain.model\")\n",
        "from gensim.models import FastText\n",
        "domain_model = FastText.load(\"domain.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12qXtrY1tzTN",
        "outputId": "de6bc514-df50-4e56-f8d9-a7a889287c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "domain_embedding_dim = 100\n",
        "\n",
        "domain_embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        domain_embedding_matrix.append(domain_model[word])\n",
        "    except:\n",
        "        domain_embedding_matrix.append([0]*domain_embedding_dim)\n",
        "domain_embedding_matrix = np.array(domain_embedding_matrix)\n",
        "domain_embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P8Z63ef9JLo"
      },
      "source": [
        "## Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm1n9Fkd3R1i",
        "outputId": "c4601f8b-082c-413f-a176-33546f31e308"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# EMBEDDING_DIM = syntactic_embedding_dim + semantic_embedding_dim + domain_embedding_dim\n",
        "# embedding_matrix = np.concatenate((syntactic_embedding_matrix, semantic_embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "# embedding_matrix.shape\n",
        "EMBEDDING_DIM = semantic_embedding_dim + domain_embedding_dim\n",
        "embedding_matrix = np.concatenate((semantic_embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "embedding_matrix.shape\n",
        "# EMBEDDING_DIM = domain_embedding_dim\n",
        "# embedding_matrix = domain_embedding_matrix\n",
        "# embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DH1-QCV9kZw"
      },
      "source": [
        "# Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPQNe3cGXFAk"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vThHga2PzBE2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Reference\n",
        "# https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class CosineAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, eps=1e-10, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        q_norm = q / (q.norm(p=2, dim=-1, keepdim=True) + self.eps)\n",
        "        k_norm = k / (k.norm(p=2, dim=-1, keepdim=True) + self.eps)\n",
        "        attention = torch.bmm(q_norm, k_norm.permute(0, 2, 1))\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference\n",
        "# https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class DotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1))\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "KvsPdCyRHplR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference\n",
        "# https://github.com/ROBINADC/BiGRU-CRF-with-Attention-for-NER\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1))\n",
        "        attention *= k.size(-1) ** -0.5\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "SAEQcYkoHt0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bODKt_5akn0"
      },
      "source": [
        "## Slot Filling/Tagging model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qoti5qtk9mTo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from flair.data import Sentence\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiGRU_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, crf=True, attention_method=None, n_layer = 1, attention_position=False):\n",
        "        super(BiGRU_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.crf = crf\n",
        "        self.n_layer = n_layer\n",
        "        self.attention_position = attention_position\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "\n",
        "        # self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "        #                     num_layers=3, bidirectional=True)\n",
        "        if self.attention_position == True:\n",
        "            self.gru_1 = nn.GRU(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "            self.gru_2 = nn.GRU(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        else:\n",
        "            self.gru = nn.GRU(embedding_dim, hidden_dim // 2,\n",
        "                                num_layers=self.n_layer, bidirectional=True)\n",
        "\n",
        "        # self.attention = nn.Transformer(hidden_dim, nhead=10, num_encoder_layers=1).encoder\n",
        "        self.attention_method = attention_method\n",
        "\n",
        "        if self.attention_method != None:\n",
        "            self.linear_q = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "            self.linear_k = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "            self.linear_v = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "            if self.attention_method == 'cosine':\n",
        "                self.attention = CosineAttention()\n",
        "            elif self.attention_method == 'dot':\n",
        "                self.attention = DotProductAttention()\n",
        "            elif self.attention_method == 'scaled_dot':\n",
        "                self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        # Maps the output of the GRU into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    # def init_hidden(self):\n",
        "    #     return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "    #             torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    def init_hidden(self):\n",
        "        if self.attention_position == True:\n",
        "            torch.randn(self.n_layer*2, 1, self.hidden_dim // 2).to(device)\n",
        "        else:\n",
        "            return torch.randn(self.n_layer*2, 1, self.hidden_dim // 2).to(device)\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # feats [L,9]\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # init_alphas [1,9]\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_gru_features(self, sentence):\n",
        "        # N: batch size\n",
        "        # L: sequence length\n",
        "        # D: 2 if bidirectional=True otherwise 1\n",
        "        # H_in: input size\n",
        "        # H_out: hidden size\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        # sentence = Sentence(\" \".join(sentence), use_tokenizer=False)\n",
        "        # embeds = self.word_embeds.embed(sentence)\n",
        "        # embeds = torch.stack([i.embedding for i in sentence])\n",
        "        # embeds = embeds.view(len(sentence), 1, -1).to(device)\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # sentence sentence torch.Size([8]), (L)\n",
        "        # embeds torch.Size([8, 1, 50]), (L,N,H_in)\n",
        "        # lstm_out torch.Size([8, 1, 50]), (L,N,D*H_out)\n",
        "        # self.hidden[0] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "        # self.hidden[1] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "        if self.attention_method == None:\n",
        "            gru_out, self.hidden = self.gru(embeds, self.hidden)\n",
        "            gru_out = gru_out.view(len(sentence), self.hidden_dim)\n",
        "            # gru_out after view torch.Size([8, 50])\n",
        "            gru_feats = self.hidden2tag(gru_out)\n",
        "            # gru_feats torch.Size([8, 9])\n",
        "\n",
        "        # attention_out = self.attention(lstm_out)\n",
        "        # attention_out = attention_out.view(len(sentence), self.hidden_dim)\n",
        "        # lstm_feats = self.hidden2tag(attention_out)\n",
        "        else:\n",
        "            if self.attention_position == True:\n",
        "                gru_out, self.hidden = self.gru_1(embeds, self.hidden)\n",
        "                gru_out = gru_out.permute(1,0,2)\n",
        "                q = self.linear_q(gru_out)\n",
        "                k = self.linear_k(gru_out)\n",
        "                v = self.linear_v(gru_out)\n",
        "                output, attention = self.attention(q,k,v)\n",
        "                self.hidden = self.init_hidden()\n",
        "                gru_out, self.hidden = self.gru_2(output, self.hidden)\n",
        "                gru_out = gru_out.view(len(sentence), self.hidden_dim)\n",
        "                gru_feats = self.hidden2tag(gru_out)\n",
        "            else:\n",
        "                gru_out, self.hidden = self.gru(embeds, self.hidden)\n",
        "                gru_out = gru_out.permute(1,0,2)\n",
        "                q = self.linear_q(gru_out)\n",
        "                k = self.linear_k(gru_out)\n",
        "                v = self.linear_v(gru_out)\n",
        "                output, attention = self.attention(q,k,v)\n",
        "                output = output.view(len(sentence), self.hidden_dim)\n",
        "                gru_feats = self.hidden2tag(output)\n",
        "\n",
        "        return gru_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_gru_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiGRU\n",
        "        gru_feats = self._get_gru_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        # score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "\n",
        "        if self.crf:\n",
        "            # Find the best path, given the features.\n",
        "            score, tag_seq = self._viterbi_decode(gru_feats)\n",
        "        else:\n",
        "            score = None\n",
        "            tag_seq = torch.max(F.softmax(gru_feats, dim=1), dim=1).indices.tolist()\n",
        "\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2-sKZd8FZDf"
      },
      "source": [
        "#### Function for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f91CWQAdFcyC"
      },
      "outputs": [],
      "source": [
        "# def cal_acc(model, input_index, output_index):\n",
        "#     ground_truth = []\n",
        "#     predicted = []\n",
        "#     for i,idxs in enumerate(input_index):\n",
        "#         ground_truth += output_index[i]\n",
        "#         score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "#         predicted += pred\n",
        "#     accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "#     return predicted, ground_truth, accuracy\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "def cal_f1(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    # accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    each_score = f1_score(ground_truth, predicted, average=None, labels=[3,6,8,7,4,2]) # T,S,C,D,P,O\n",
        "    mean_score = f1_score(ground_truth, predicted, average='micro')\n",
        "    return predicted, ground_truth, each_score, mean_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaPmSoqNEkIH"
      },
      "source": [
        "#### Initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1AiIH0XEo47"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "# model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, crf=True, attention_method=None, n_layer = 1, attention_position=True).to(device)\n",
        "\n",
        "model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                  crf = True, attention_method = None,\n",
        "                  n_layer = 1, attention_position = False).to(device)\n",
        "\n",
        "# model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et311Pp2E3k1"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7479658-04f0-45c3-ce02-856bd9b89ec4",
        "id": "uthvwmtAQY8y"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 9702.79, train each f1: [0.9758 0.9939 0.986  0.9329 0.999  0.9946], train mean f1: 0.9937, val loss: 1117.81, val each f1: [0.9737 0.9924 0.9733 0.9256 0.9989 0.993 ], val mean f1: 0.9918, time: 786.66s\n",
            "Epoch:2, Training loss: 2229.80, train each f1: [0.9873 0.9984 0.9949 0.9728 0.9997 0.9978], train mean f1: 0.9974, val loss: 830.07, val each f1: [0.9758 0.9949 0.9832 0.9543 0.9991 0.9949], val mean f1: 0.9941, time: 765.04s\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "# bptt = 100\n",
        "dictionary_data = {}\n",
        "\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "    # for i, idxs in enumerate(train_data):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        # sentence_in = idxs\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_f1 functions you implemented as required\n",
        "    _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "    _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "    dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "    dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "    dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "    dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "    dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "    print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'best_model.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n",
        "\n",
        "\n",
        "# The log below is the sample output for this section\n",
        "# Please make sure you keep your own running log for submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qstlc-K-I_i",
        "outputId": "31fcd521-51d4-49cd-b3e2-e858df74c48d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiGRU_CRF(\n",
              "  (word_embeds): Embedding(11243, 300)\n",
              "  (gru): GRU(300, 50, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=100, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "torch.save(model,'model')\n",
        "model = torch.load('model')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqO86OgsGCpK"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PENa3TFeGDgG"
      },
      "outputs": [],
      "source": [
        "def test(model, input_index):\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    return predicted\n",
        "\n",
        "y_pred = test(model,test_input_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSJ2kKNUf-hS"
      },
      "outputs": [],
      "source": [
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_pred_decode = decode_output(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOSnBv8jjm49"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for i in range(len(y_pred_decode)):\n",
        "  for token in y_pred_decode[i].split():\n",
        "    results.append(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxMILiddlELJ"
      },
      "outputs": [],
      "source": [
        "results.insert(0, 'Predicted')\n",
        "id = [item for item in range(0, 2326)]\n",
        "id.insert(0, 'Id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2C4YfSYmaQd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "file = open(\"sample.csv\", \"w\")\n",
        "writer = csv.writer(file)\n",
        "\n",
        "for w in range(len(results)):\n",
        "\n",
        "  writer.writerow([id[w], results[w]])\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8-Be-Fqjgqy"
      },
      "source": [
        "# Testing and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Log9mnC_8AE6"
      },
      "source": [
        "## Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6EkmQvw94bO"
      },
      "source": [
        "### Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from flair.data import Sentence\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, crf=True, attention_method=None, n_layer = 1, attention_position=False):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.crf = crf\n",
        "        self.n_layer = n_layer\n",
        "        self.attention_position = attention_position\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "\n",
        "        # self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "        #                     num_layers=3, bidirectional=True)\n",
        "        if self.attention_position == True:\n",
        "            self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "            self.lstm_2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        else:\n",
        "            self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                                num_layers=self.n_layer, bidirectional=True)\n",
        "\n",
        "        # self.attention = nn.Transformer(hidden_dim, nhead=10, num_encoder_layers=1).encoder\n",
        "        self.attention_method = attention_method\n",
        "\n",
        "        if self.attention_method != None:\n",
        "            self.linear_q = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "            self.linear_k = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "            self.linear_v = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "            if self.attention_method == 'cosine':\n",
        "                self.attention = CosineAttention()\n",
        "            elif self.attention_method == 'dot':\n",
        "                self.attention = DotProductAttention()\n",
        "            elif self.attention_method == 'scaled_dot':\n",
        "                self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    # def init_hidden(self):\n",
        "    #     return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "    #             torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # feats [L,9]\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # init_alphas [1,9]\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        # N: batch size\n",
        "        # L: sequence length\n",
        "        # D: 2 if bidirectional=True otherwise 1\n",
        "        # H_in: input size\n",
        "        # H_out: hidden size\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        # sentence = Sentence(\" \".join(sentence), use_tokenizer=False)\n",
        "        # embeds = self.word_embeds.embed(sentence)\n",
        "        # embeds = torch.stack([i.embedding for i in sentence])\n",
        "        # embeds = embeds.view(len(sentence), 1, -1).to(device)\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # sentence sentence torch.Size([8]), (L)\n",
        "        # embeds torch.Size([8, 1, 50]), (L,N,H_in)\n",
        "        # lstm_out torch.Size([8, 1, 50]), (L,N,D*H_out)\n",
        "        # self.hidden[0] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "        # self.hidden[1] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "        if self.attention_method == None:\n",
        "            lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "            lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "            # lstm_out after view torch.Size([8, 50])\n",
        "            lstm_feats = self.hidden2tag(lstm_out)\n",
        "            # lstm_feats torch.Size([8, 9])\n",
        "\n",
        "        # attention_out = self.attention(lstm_out)\n",
        "        # attention_out = attention_out.view(len(sentence), self.hidden_dim)\n",
        "        # lstm_feats = self.hidden2tag(attention_out)\n",
        "        else:\n",
        "            if self.attention_position == True:\n",
        "                lstm_out, self.hidden = self.lstm_1(embeds, self.hidden)\n",
        "                lstm_out = lstm_out.permute(1,0,2)\n",
        "                q = self.linear_q(lstm_out)\n",
        "                k = self.linear_k(lstm_out)\n",
        "                v = self.linear_v(lstm_out)\n",
        "                output, attention = self.attention(q,k,v)\n",
        "                self.hidden = self.init_hidden()\n",
        "                lstm_out, self.hidden = self.lstm_2(output, self.hidden)\n",
        "                lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "                lstm_feats = self.hidden2tag(lstm_out)\n",
        "            else:\n",
        "                lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "                lstm_out = lstm_out.permute(1,0,2)\n",
        "                q = self.linear_q(lstm_out)\n",
        "                k = self.linear_k(lstm_out)\n",
        "                v = self.linear_v(lstm_out)\n",
        "                output, attention = self.attention(q,k,v)\n",
        "                output = output.view(len(sentence), self.hidden_dim)\n",
        "                lstm_feats = self.hidden2tag(output)\n",
        "\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        # score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "\n",
        "        if self.crf:\n",
        "            # Find the best path, given the features.\n",
        "            score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        else:\n",
        "            score = None\n",
        "            tag_seq = torch.max(F.softmax(lstm_feats, dim=1), dim=1).indices.tolist()\n",
        "\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "kRxg1AuMQMjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "# model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, crf=True, attention_method=None, n_layer = 1, attention_position=True).to(device)\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                  crf = True, attention_method = None,\n",
        "                  n_layer = 1, attention_position = False).to(device)\n",
        "\n",
        "# model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "Ta1xDmZhaviP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "outputId": "d3bc973f-a230-4c2d-87cb-9a90ecba126e",
        "id": "vy0k6Ac5vt5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 12183.13, train each f1: [0.9722 0.9912 0.9851 0.919  0.9988 0.9937], train mean f1: 0.9925, val loss: 1203.29, val each f1: [0.9688 0.9887 0.9727 0.9175 0.9987 0.9919], val mean f1: 0.9905, time: 875.52s\n",
            "Epoch:2, Training loss: 2563.02, train each f1: [0.9852 0.9972 0.9944 0.9588 0.9995 0.9972], train mean f1: 0.9967, val loss: 836.34, val each f1: [0.9764 0.9941 0.9841 0.9542 0.9991 0.995 ], val mean f1: 0.9941, time: 832.26s\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "# bptt = 100\n",
        "dictionary_data = {}\n",
        "\n",
        "for epoch in range(2):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "    # for i, idxs in enumerate(train_data):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        # sentence_in = idxs\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_f1 functions you implemented as required\n",
        "    _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "    _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "    dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "    dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "    dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "    dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "    dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "    print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'baseline.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n",
        "\n",
        "\n",
        "# The log below is the sample output for this section\n",
        "# Please make sure you keep your own running log for submission"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvaRQreg_1b0",
        "outputId": "6ebfc4db-c512-4b9e-e7c7-0ec631820662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"baseline.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['baseline', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "with open(\"best_model.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['best_model', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1(T)\", \"T-F1(S)\", \"T-F1(C)\", \"T-F1(D)\", \"T-F1(P)\", \"T-F1(O)\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZXREbj_4D7",
        "outputId": "838d9ba8-20d7-40c0-bc03-b79e8e6b99e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model         T-F1(T)    T-F1(S)    T-F1(C)    T-F1(D)    T-F1(P)    T-F1(O)      T-F1\n",
            "----------  ---------  ---------  ---------  ---------  ---------  ---------  --------\n",
            "baseline     0.976438   0.994115   0.984088   0.954198   0.999111   0.994955  0.994094\n",
            "best_model   0.975795   0.99487    0.983237   0.954315   0.999111   0.9949    0.994064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk0S2FZw0LVi"
      },
      "source": [
        "## Ablation Study - different input embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvt26wvF96yK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d45fe99-9cc8-472f-f41f-5225554c5b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedding_method': ['semantic'], 'attention_method': None, 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 16337.94, train each f1: [0.9651 0.9842 0.9647 0.832  0.998  0.9887], train mean f1: 0.9866, val loss: 2076.62, val each f1: [0.9642 0.9791 0.9467 0.8345 0.997  0.9865], val mean f1: 0.9839, time: 705.06s\n",
            "Epoch:2, Training loss: 4225.64, train each f1: [0.9826 0.995  0.9904 0.9275 0.999  0.9956], train mean f1: 0.9948, val loss: 1410.38, val each f1: [0.9732 0.9899 0.9724 0.9016 0.9976 0.9917], val mean f1: 0.9903, time: 688.81s\n",
            "{'embedding_method': ['domain'], 'attention_method': None, 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 11739.29, train each f1: [0.9709 0.993  0.987  0.9226 0.9987 0.9951], train mean f1: 0.9935, val loss: 1158.01, val each f1: [0.9628 0.9929 0.978  0.9253 0.9985 0.9934], val mean f1: 0.9918, time: 529.11s\n",
            "Epoch:2, Training loss: 2140.28, train each f1: [0.9908 0.9984 0.9974 0.9776 0.9997 0.999 ], train mean f1: 0.9984, val loss: 842.27, val each f1: [0.9715 0.9953 0.9856 0.9455 0.9987 0.9953], val mean f1: 0.9941, time: 545.38s\n",
            "{'embedding_method': ['semantic', 'domain', 'syntactic'], 'attention_method': None, 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 9971.53, train each f1: [0.9742 0.9936 0.9859 0.9307 0.9993 0.9945], train mean f1: 0.9935, val loss: 1082.20, val each f1: [0.9687 0.9929 0.9721 0.9371 0.9992 0.993 ], val mean f1: 0.9917, time: 898.23s\n",
            "Epoch:2, Training loss: 2194.22, train each f1: [0.983  0.9982 0.9959 0.9712 0.9996 0.9975], train mean f1: 0.9970, val loss: 816.87, val each f1: [0.9743 0.9949 0.9826 0.9541 0.9994 0.9947], val mean f1: 0.9939, time: 857.53s\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import pickle\n",
        "configs = [\n",
        "    {\n",
        "        \"embedding_method\": ['semantic'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    {\n",
        "        \"embedding_method\": ['domain'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    # Best model, already tested\n",
        "\n",
        "    # {\n",
        "    #     \"embedding_method\": ['semantic', 'domain'],\n",
        "    #     \"attention_method\": None,\n",
        "    #     \"crf\": True,\n",
        "    #     \"n_layer\": 1,\n",
        "    #     \"attention_position\": False,\n",
        "    # },\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain', 'syntactic'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "]\n",
        "\n",
        "count = 0\n",
        "for config in configs:\n",
        "    count += 1\n",
        "    dictionary_data = {}\n",
        "    print(config)\n",
        "    ### input embedding\n",
        "    embedding_matrix = None\n",
        "    for embedding_method in config['embedding_method']:\n",
        "        if embedding_matrix is None:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = semantic_embedding_matrix\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = domain_embedding_matrix\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = syntactic_embedding_matrix\n",
        "        else:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, semantic_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, syntactic_embedding_matrix), axis=1)\n",
        "\n",
        "\n",
        "    EMBEDDING_DIM = embedding_matrix.shape[1]\n",
        "    HIDDEN_DIM = 100\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                      crf = config['crf'], attention_method = config['attention_method'],\n",
        "                      n_layer = config['n_layer'], attention_position = config['attention_position']).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "    print('Starting Training')\n",
        "\n",
        "    for epoch in range(2):\n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "        # for i, idxs in enumerate(train_data):\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        # Call the cal_f1 functions you implemented as required\n",
        "        _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "        _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, idxs in enumerate(val_input_index):\n",
        "            tags_index = val_output_index[i]\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            val_loss+=loss.item()\n",
        "        time2 = datetime.datetime.now()\n",
        "        dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "        dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "        dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "        dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "        dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "        dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "        print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'embedding' + str(count) + '.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"embedding1.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['sementic', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "with open(\"embedding2.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['domain', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "with open(\"embedding3.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['sementic_domain_syntactic', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "with open(\"best_model.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['sementic_domain', vef1[0], vef1[1], vef1[2], vef1[3], vef1[4], vef1[5], vmf1])\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1(T)\", \"T-F1(S)\", \"T-F1(C)\", \"T-F1(D)\", \"T-F1(P)\", \"T-F1(O)\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBcFwdxu58Pf",
        "outputId": "ed2b7dba-dc21-4861-b491-b9165b756593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                        T-F1(T)    T-F1(S)    T-F1(C)    T-F1(D)    T-F1(P)    T-F1(O)      T-F1\n",
            "-------------------------  ---------  ---------  ---------  ---------  ---------  ---------  --------\n",
            "sementic                    0.973214   0.989896   0.972443   0.901554   0.99759    0.991693  0.990316\n",
            "domain                      0.971546   0.995324   0.98564    0.945545   0.99873    0.995289  0.994094\n",
            "sementic_domain_syntactic   0.974341   0.994876   0.982606   0.954082   0.999365   0.994717  0.993884\n",
            "sementic_domain             0.975795   0.99487    0.983237   0.954315   0.999111   0.9949    0.994064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation Study - different attention strategy"
      ],
      "metadata": {
        "id": "civEJKC0rkDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import pickle\n",
        "configs = [\n",
        "\n",
        "    # Best model, already tested\n",
        "\n",
        "    # {\n",
        "    #     \"embedding_method\": ['semantic', 'domain'],\n",
        "    #     \"attention_method\": None,\n",
        "    #     \"crf\": True,\n",
        "    #     \"n_layer\": 1,\n",
        "    #     \"attention_position\": False,\n",
        "    # },\n",
        "\n",
        "\n",
        "    # Attention score calculation\n",
        "\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": 'cosine',\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": 'dot',\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": 'scaled_dot',\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "\n",
        "    # Attention position\n",
        "\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": 'cosine',\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 2,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": 'cosine',\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 2,\n",
        "        \"attention_position\": True,\n",
        "    },\n",
        "]\n",
        "\n",
        "count = 0\n",
        "for config in configs:\n",
        "    count += 1\n",
        "    dictionary_data = {}\n",
        "    print(config)\n",
        "    ### input embedding\n",
        "    embedding_matrix = None\n",
        "    for embedding_method in config['embedding_method']:\n",
        "        if embedding_matrix is None:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = semantic_embedding_matrix\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = domain_embedding_matrix\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = syntactic_embedding_matrix\n",
        "        else:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, semantic_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, syntactic_embedding_matrix), axis=1)\n",
        "\n",
        "\n",
        "    EMBEDDING_DIM = embedding_matrix.shape[1]\n",
        "    HIDDEN_DIM = 100\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                      crf = config['crf'], attention_method = config['attention_method'],\n",
        "                      n_layer = config['n_layer'], attention_position = config['attention_position']).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "    print('Starting Training')\n",
        "\n",
        "    for epoch in range(2):\n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "        # for i, idxs in enumerate(train_data):\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        # Call the cal_f1 functions you implemented as required\n",
        "        _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "        _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, idxs in enumerate(val_input_index):\n",
        "            tags_index = val_output_index[i]\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            val_loss+=loss.item()\n",
        "        time2 = datetime.datetime.now()\n",
        "        dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "        dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "        dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "        dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "        dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "        dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "        print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'attention' + str(count) + '.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f0b4d8-c078-40ab-9d23-ea672ae2ea95",
        "id": "pWCljivFu-0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': 'cosine', 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 27135.23, train each f1: [0.9448 0.9757 0.9625 0.78   0.9946 0.9893], train mean f1: 0.9840, val loss: 2567.61, val each f1: [0.9396 0.9697 0.9427 0.7967 0.9948 0.987 ], val mean f1: 0.9811, time: 530.85s\n",
            "Epoch:2, Training loss: 6112.79, train each f1: [0.965  0.9881 0.9805 0.9014 0.9964 0.995 ], train mean f1: 0.9916, val loss: 2028.54, val each f1: [0.952  0.9832 0.9634 0.8629 0.9962 0.9913], val mean f1: 0.9870, time: 508.64s\n",
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': 'dot', 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 48442.99, train each f1: [0.3488 0.608  0.555  0.0277 0.8459 0.8825], train mean f1: 0.8275, val loss: 19255.22, val each f1: [0.3529 0.6091 0.5458 0.0487 0.8353 0.8822], val mean f1: 0.8257, time: 499.01s\n",
            "Epoch:2, Training loss: 60905.58, train each f1: [0.5781 0.8566 0.2205 0.2065 0.7392 0.8807], train mean f1: 0.8384, val loss: 18428.22, val each f1: [0.5846 0.866  0.2177 0.2304 0.736  0.8801], val mean f1: 0.8391, time: 503.07s\n",
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': 'scaled_dot', 'crf': True, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 18714.03, train each f1: [0.9653 0.9878 0.9702 0.8979 0.9983 0.9911], train mean f1: 0.9893, val loss: 1546.29, val each f1: [0.9636 0.9836 0.9527 0.892  0.9985 0.9888], val mean f1: 0.9866, time: 506.48s\n",
            "Epoch:2, Training loss: 3226.96, train each f1: [0.977  0.9965 0.9912 0.9553 0.9994 0.9962], train mean f1: 0.9955, val loss: 1021.67, val each f1: [0.9716 0.9925 0.9788 0.9286 0.9994 0.9934], val mean f1: 0.9923, time: 510.62s\n",
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': 'cosine', 'crf': True, 'n_layer': 2, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 31880.05, train each f1: [0.954  0.9808 0.9526 0.7893 0.9966 0.9904], train mean f1: 0.9853, val loss: 2679.94, val each f1: [0.9472 0.9785 0.9383 0.7946 0.9959 0.9882], val mean f1: 0.9828, time: 571.32s\n",
            "Epoch:2, Training loss: 6000.63, train each f1: [0.9724 0.99   0.9814 0.897  0.9981 0.9948], train mean f1: 0.9924, val loss: 1825.53, val each f1: [0.9662 0.9871 0.9651 0.8886 0.9973 0.9927], val mean f1: 0.9897, time: 579.71s\n",
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': 'cosine', 'crf': True, 'n_layer': 2, 'attention_position': True}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 30155.55, train each f1: [0.9474 0.9776 0.9556 0.768  0.9961 0.9906], train mean f1: 0.9848, val loss: 2365.97, val each f1: [0.9348 0.9731 0.9328 0.7686 0.9954 0.9884], val mean f1: 0.9814, time: 554.75s\n",
            "Epoch:2, Training loss: 5380.64, train each f1: [0.9697 0.9927 0.9832 0.9073 0.9988 0.9957], train mean f1: 0.9933, val loss: 1566.54, val each f1: [0.9557 0.9866 0.9616 0.8629 0.998  0.9922], val mean f1: 0.9884, time: 552.44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"attention1.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['cosine', vmf1])\n",
        "\n",
        "with open(\"attention2.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['dot', vmf1])\n",
        "\n",
        "with open(\"attention3.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['scaled_dot', vmf1])\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfnrft54An5P",
        "outputId": "0e7fc4bc-23e9-49e5-9b6c-b08d5b0b9cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model           T-F1\n",
            "----------  --------\n",
            "cosine      0.986958\n",
            "dot         0.83909\n",
            "scaled_dot  0.992295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"attention4.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['cosine_attention_after_layer_2', vmf1])\n",
        "\n",
        "with open(\"attention5.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['cosine_attention_after_layer_1', vmf1])\n",
        "\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g2BkwX5BdZd",
        "outputId": "65f961ec-fa35-4699-d625-f9063c8aa608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model                               T-F1\n",
            "------------------------------  --------\n",
            "cosine_attention_after_layer_2  0.989716\n",
            "cosine_attention_after_layer_1  0.988427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation Study - different Stacked layer or # of encoder/decoder strategy"
      ],
      "metadata": {
        "id": "DH5QVg6NrkGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import pickle\n",
        "configs = [\n",
        "\n",
        "    # Best model, already tested\n",
        "\n",
        "    # {\n",
        "    #     \"embedding_method\": ['semantic', 'domain'],\n",
        "    #     \"attention_method\": None,\n",
        "    #     \"crf\": True,\n",
        "    #     \"n_layer\": 1,\n",
        "    #     \"attention_position\": False,\n",
        "    # },\n",
        "\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 2,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": True,\n",
        "        \"n_layer\": 3,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "\n",
        "]\n",
        "\n",
        "count = 0\n",
        "for config in configs:\n",
        "    count += 1\n",
        "    dictionary_data = {}\n",
        "    print(config)\n",
        "    ### input embedding\n",
        "    embedding_matrix = None\n",
        "    for embedding_method in config['embedding_method']:\n",
        "        if embedding_matrix is None:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = semantic_embedding_matrix\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = domain_embedding_matrix\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = syntactic_embedding_matrix\n",
        "        else:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, semantic_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, syntactic_embedding_matrix), axis=1)\n",
        "\n",
        "\n",
        "    EMBEDDING_DIM = embedding_matrix.shape[1]\n",
        "    HIDDEN_DIM = 100\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                      crf = config['crf'], attention_method = config['attention_method'],\n",
        "                      n_layer = config['n_layer'], attention_position = config['attention_position']).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "    print('Starting Training')\n",
        "\n",
        "    for epoch in range(2):\n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "        # for i, idxs in enumerate(train_data):\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        # Call the cal_f1 functions you implemented as required\n",
        "        _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "        _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, idxs in enumerate(val_input_index):\n",
        "            tags_index = val_output_index[i]\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            val_loss+=loss.item()\n",
        "        time2 = datetime.datetime.now()\n",
        "        dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "        dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "        dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "        dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "        dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "        dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "        print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'layer' + str(count) + '.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n"
      ],
      "metadata": {
        "id": "tOvDds6IT80_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a97b93-d40d-4291-d2e5-7678b0975efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': None, 'crf': True, 'n_layer': 2, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 11983.37, train each f1: [0.9728 0.9932 0.9841 0.9261 0.999  0.9939], train mean f1: 0.9929, val loss: 1127.59, val each f1: [0.9705 0.9905 0.9749 0.9315 0.9991 0.9927], val mean f1: 0.9915, time: 906.04s\n",
            "Epoch:2, Training loss: 2442.34, train each f1: [0.9864 0.9981 0.9952 0.9658 0.9995 0.9975], train mean f1: 0.9971, val loss: 829.60, val each f1: [0.978  0.9943 0.983  0.9486 0.999  0.9949], val mean f1: 0.9940, time: 888.38s\n",
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': None, 'crf': True, 'n_layer': 3, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 16251.68, train each f1: [0.9639 0.9899 0.9855 0.9119 0.9985 0.9929], train mean f1: 0.9914, val loss: 1355.67, val each f1: [0.9617 0.9891 0.9745 0.9016 0.998  0.991 ], val mean f1: 0.9895, time: 897.46s\n",
            "Epoch:2, Training loss: 2986.61, train each f1: [0.9811 0.9953 0.9942 0.9586 0.9993 0.9964], train mean f1: 0.9958, val loss: 928.71, val each f1: [0.9776 0.9932 0.9808 0.9503 0.9992 0.9944], val mean f1: 0.9936, time: 887.64s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"best_model.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['1_layer', vmf1])\n",
        "\n",
        "with open(\"layer1.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['2_layer', vmf1])\n",
        "\n",
        "with open(\"layer2.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['3_layer', vmf1])\n",
        "\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIiU5GmlCTXx",
        "outputId": "6ac36b48-940b-4164-f488-943daf17a0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model        T-F1\n",
            "-------  --------\n",
            "1_layer  0.994064\n",
            "2_layer  0.994004\n",
            "3_layer  0.993554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation Study - with/without CRF"
      ],
      "metadata": {
        "id": "K6_HvYjjrkIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import pickle\n",
        "configs = [\n",
        "\n",
        "\n",
        "    # Best model, already tested\n",
        "\n",
        "    # {\n",
        "    #     \"embedding_method\": ['semantic', 'domain'],\n",
        "    #     \"attention_method\": None,\n",
        "    #     \"crf\": True,\n",
        "    #     \"n_layer\": 1,\n",
        "    #     \"attention_position\": False,\n",
        "    # },\n",
        "\n",
        "    {\n",
        "        \"embedding_method\": ['semantic', 'domain'],\n",
        "        \"attention_method\": None,\n",
        "        \"crf\": False,\n",
        "        \"n_layer\": 1,\n",
        "        \"attention_position\": False,\n",
        "    },\n",
        "\n",
        "]\n",
        "\n",
        "count = 0\n",
        "for config in configs:\n",
        "    count += 1\n",
        "    dictionary_data = {}\n",
        "    print(config)\n",
        "    ### input embedding\n",
        "    embedding_matrix = None\n",
        "    for embedding_method in config['embedding_method']:\n",
        "        if embedding_matrix is None:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = semantic_embedding_matrix\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = domain_embedding_matrix\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = syntactic_embedding_matrix\n",
        "        else:\n",
        "            if embedding_method == 'semantic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, semantic_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'domain':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "            elif embedding_method == 'syntactic':\n",
        "                embedding_matrix = np.concatenate((embedding_matrix, syntactic_embedding_matrix), axis=1)\n",
        "\n",
        "\n",
        "    EMBEDDING_DIM = embedding_matrix.shape[1]\n",
        "    HIDDEN_DIM = 100\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = BiGRU_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,\n",
        "                      crf = config['crf'], attention_method = config['attention_method'],\n",
        "                      n_layer = config['n_layer'], attention_position = config['attention_position']).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "    print('Starting Training')\n",
        "\n",
        "    for epoch in range(2):\n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "        # for i, idxs in enumerate(train_data):\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        # Call the cal_f1 functions you implemented as required\n",
        "        _, _, train_each_f1, train_mean_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "        _, _, val_each_f1, val_mean_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "\n",
        "\n",
        "        val_loss = 0\n",
        "        for i, idxs in enumerate(val_input_index):\n",
        "            tags_index = val_output_index[i]\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            val_loss+=loss.item()\n",
        "        time2 = datetime.datetime.now()\n",
        "        dictionary_data[str(epoch)+'tloss'] = train_loss\n",
        "        dictionary_data[str(epoch)+'vloss'] = val_loss\n",
        "        dictionary_data[str(epoch)+'tef1'] = train_each_f1\n",
        "        dictionary_data[str(epoch)+'vef1'] = val_each_f1\n",
        "        dictionary_data[str(epoch)+'tmf1'] = train_mean_f1\n",
        "        dictionary_data[str(epoch)+'vmf1'] = val_mean_f1\n",
        "\n",
        "        print(\"Epoch:{:d}, Training loss: {:.2f}, train each f1: {}, train mean f1: {:.4f}, val loss: {:.2f}, val each f1: {}, val mean f1: {:.4f}, time: {:.2f}s\".format(epoch+1, train_loss, train_each_f1.round(4), train_mean_f1, val_loss, val_each_f1.round(4), val_mean_f1, (time2-time1).total_seconds()))\n",
        "    # The log below is the sample output for this section\n",
        "    # Please make sure you keep your own running log for submission\n",
        "\n",
        "    filename = 'crf' + str(count) + '.pkl'\n",
        "    a_file = open(filename, \"wb\")\n",
        "    pickle.dump(dictionary_data, a_file)\n",
        "    a_file.close()\n",
        "\n",
        "    # a_file = open(\"data.pkl\", \"rb\")\n",
        "    # output = pickle.load(a_file)\n",
        "    # print(output)\n",
        "    # {'a': 1, 'b': 2}\n",
        "    # a_file.close()\n"
      ],
      "metadata": {
        "id": "168MmenbT9jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8b91cd-dd49-4360-9e4f-191cda25a4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedding_method': ['semantic', 'domain'], 'attention_method': None, 'crf': False, 'n_layer': 1, 'attention_position': False}\n",
            "Starting Training\n",
            "Epoch:1, Training loss: 9962.71, train each f1: [0.9722 0.9921 0.9787 0.9256 0.998  0.9934], train mean f1: 0.9919, val loss: 1129.10, val each f1: [0.9693 0.9901 0.9691 0.9244 0.998  0.9919], val mean f1: 0.9903, time: 672.84s\n",
            "Epoch:2, Training loss: 2280.04, train each f1: [0.9855 0.998  0.9912 0.9682 0.9987 0.9973], train mean f1: 0.9966, val loss: 838.07, val each f1: [0.9768 0.9946 0.9809 0.9497 0.998  0.9944], val mean f1: 0.9934, time: 673.03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_list = []\n",
        "\n",
        "with open(\"best_model.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['use_crf', vmf1])\n",
        "\n",
        "with open(\"crf1.pkl\", \"rb\") as f:\n",
        "    output = pickle.load(f)\n",
        "    vef1 = output['1vef1']\n",
        "    vmf1 = output['1vmf1']\n",
        "    dim_list.append(['no_crf', vmf1])\n",
        "\n",
        "\n",
        "#define header names\n",
        "col_names = [\"Model\", \"T-F1\"]\n",
        "\n",
        "#display table\n",
        "print(tabulate(dim_list, headers=col_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whwA2EfmDGH8",
        "outputId": "17657985-ebf8-44af-c5ad-c24167fec535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model        T-F1\n",
            "-------  --------\n",
            "use_crf  0.994064\n",
            "no_crf   0.993434\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}