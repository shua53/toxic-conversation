{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_200+200,fasttext,sgd,lr=0.01,crf=true.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data And Input"
      ],
      "metadata": {
        "id": "PCrCzhqoysCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Download and Load"
      ],
      "metadata": {
        "id": "dLi4x7XSysOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "drive = None\n",
        "def authenticate():\n",
        "    global drive\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "#Download files\n",
        "def downloadFiles(fileIds):\n",
        "    authenticate()\n",
        "    for fileId in fileIds:    \n",
        "        downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
        "        downloaded.GetContentFile(fileId[0])"
      ],
      "metadata": {
        "id": "RE_R8hCDzEzM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download file if not existing\n",
        "try:\n",
        "  _ = open(\"train.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"train.csv\", \"1pRTJ3aTh1yZV2ZN7Fof2NSt1c137SzYw\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"val.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"val.csv\", \"1khO0wHBC8bBzLVH4G09NhKTHHfAwBIna\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"test.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"test.csv\", \"1-E3dhTaMhG5oRKS9HGF9ZTTzsOKc_D14\"]])\n",
        "\n",
        "try:\n",
        "  _ = open(\"dota.csv\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"dota.csv\", \"1DCsO0uICmtabGiy8MQAYPl0xeDwhFP5S\"]])\n",
        "\n",
        "# dimension 25\n",
        "# try:\n",
        "#   _ = open(\"domain.model\", \"r\")\n",
        "# except:\n",
        "#   downloadFiles([[\"domain.model\", \"1KHFu7kJBwlopIqlKrVaujvRt1AoJzcbt\"]])\n",
        "\n",
        "# dimension50\n",
        "try:\n",
        "  _ = open(\"domain.model\", \"r\")\n",
        "except:\n",
        "  downloadFiles([[\"domain.model\", \"14zkvDnEk4dZZ4vzdK1RJbpGAgw_G_rty\"]])\n"
      ],
      "metadata": {
        "id": "flVlngEM0nTU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(file_name, test=False):\n",
        "    f = pd.read_csv(file_name)\n",
        "\n",
        "    temp1 = f['sents'].tolist()\n",
        "    input_data = [sent.lower().split() for sent in temp1]\n",
        "\n",
        "    if not test:\n",
        "      temp2 = f['labels'].tolist()\n",
        "      target_data = [sent.split() for sent in temp2]\n",
        "\n",
        "      return input_data, target_data\n",
        "\n",
        "    return input_data\n",
        "\n",
        "train_data, target_y_train = read_data('train.csv')\n",
        "validation_data, target_y_validation = read_data('val.csv')\n",
        "test_data = read_data('test.csv', True)\n",
        "\n",
        "print(len(train_data))\n",
        "print(type(train_data[2]))\n",
        "print(train_data[2])\n",
        "print(target_y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqJx_PJo2IFX",
        "outputId": "cbb2034f-9ac0-46f6-d166-c4e0ed850e11"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26078\n",
            "<class 'list'>\n",
            "['wpe', 'wpe']\n",
            "['O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "ESpDFNNFysQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate word_to_ix and tag_to_ix"
      ],
      "metadata": {
        "id": "bR63d4tY9LjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "metadata": {
        "id": "qLhNETrW84qH"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Embedding"
      ],
      "metadata": {
        "id": "8vqpnyu9ysTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aspect 1) Syntactic Textual Feature Embedding: PoS tag information, Dependency Path, etc.\n"
      ],
      "metadata": {
        "id": "XZhIz4lIzoHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "labels = [nlp(word)[0].tag_ for word in word_list]\n",
        "\n",
        "# one-hot encoding\n",
        "syntactic_labels = dict()\n",
        "for idx,label in enumerate(set(labels)):\n",
        "  syntactic_labels[label] = [0]*len(set(labels))\n",
        "  syntactic_labels[label][idx] = 1\n",
        "\n",
        "syntactic_embedding_dim = len(set(labels))\n",
        "\n",
        "syntactic_embedding_matrix = []\n",
        "for label in labels:\n",
        "    try:\n",
        "        syntactic_embedding_matrix.append(syntactic_labels[label])\n",
        "    except:\n",
        "        syntactic_embedding_matrix.append([0]*len(set(labels)))\n",
        "syntactic_embedding_matrix = np.array(syntactic_embedding_matrix)\n",
        "syntactic_embedding_matrix.shape"
      ],
      "metadata": {
        "id": "qrEM6FYn0iDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4017e8f7-9882-4773-e8bb-d35ca65ced91"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aspect 2) Semantic Textual Feature Embedding: Word Embeddings (Word2Vec, ELMO, etc.)"
      ],
      "metadata": {
        "id": "6sdwAZgqzp8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "\n",
        "word_emb_model = api.load(\"glove-twitter-200\") \n",
        "\n",
        "semantic_embedding_dim = 200\n",
        "\n",
        "semantic_embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        semantic_embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        semantic_embedding_matrix.append([0]*semantic_embedding_dim)\n",
        "semantic_embedding_matrix = np.array(semantic_embedding_matrix)\n",
        "semantic_embedding_matrix.shape"
      ],
      "metadata": {
        "id": "3wkMU2G40lMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc33bdd-f0f4-4520-f48d-6546f0d7f837"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aspect 3) Domain Feature Embedding: Your own new feature embedding to solve this in-game chat word slot filling(tagging)."
      ],
      "metadata": {
        "id": "D6zil3Vaz4oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dota = pd.read_csv('dota.csv').dropna(subset=['key'])\n",
        "corpus = dota['key'].tolist()\n",
        "\n",
        "# Import libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Prepare training corpus for Gensim Word2Vec Skip-Gram model - List of List\n",
        "sentences=[]\n",
        "sentences=[word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "\n",
        "# Train the Gensim Word2Vec Skip-Gram model\n",
        "# domain_model = Word2Vec(sentences=sentences, size=50, window=2, min_count=1, workers=2, sg=1)\n",
        "domain_model = FastText(sentences=sentences, size=200, window=2, min_count=1, workers=2, sg=1)"
      ],
      "metadata": {
        "id": "bEptF--vvqXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e965741c-abfc-4077-b783-6e3d9010f50f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and load model\n",
        "# domain_model.save(\"domain.model\")\n",
        "# from gensim.models import Word2Vec\n",
        "# domain_model = Word2Vec.load(\"domain.model\")"
      ],
      "metadata": {
        "id": "7XmtyiYmv5Xa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domain_embedding_dim = 200\n",
        "\n",
        "domain_embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        domain_embedding_matrix.append(domain_model[word])\n",
        "    except:\n",
        "        domain_embedding_matrix.append([0]*domain_embedding_dim)\n",
        "domain_embedding_matrix = np.array(domain_embedding_matrix)\n",
        "domain_embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30qUx44W0zzU",
        "outputId": "4c3ffacd-7480-40b4-c23b-d7eb45e23ec4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Embedding Matrix"
      ],
      "metadata": {
        "id": "4P8Z63ef9JLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EMBEDDING_DIM = syntactic_embedding_dim + semantic_embedding_dim + domain_embedding_dim\n",
        "# embedding_matrix = np.concatenate((syntactic_embedding_matrix, semantic_embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "# embedding_matrix.shape\n",
        "EMBEDDING_DIM = semantic_embedding_dim + domain_embedding_dim\n",
        "embedding_matrix = np.concatenate((semantic_embedding_matrix, domain_embedding_matrix), axis=1)\n",
        "embedding_matrix.shape\n",
        "# EMBEDDING_DIM = domain_embedding_dim\n",
        "# embedding_matrix = domain_embedding_matrix\n",
        "# embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm1n9Fkd3R1i",
        "outputId": "60f3c6a3-2f9d-4ca9-98bb-8af54dfe3923"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11243, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert dataset into idxs"
      ],
      "metadata": {
        "id": "uRIpWbEV9GdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)\n",
        "train_val_input_index = train_input_index + val_input_index\n",
        "train_val_output_index = train_output_index + val_output_index\n",
        "# test_output_index = to_index(target_y_test,tag_to_ix)"
      ],
      "metadata": {
        "id": "EFIsMdcx9DA2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "_DH1-QCV9kZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "sPQNe3cGXFAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class CosineAttention(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.0, eps=1e-10, **kwargs):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        q_norm = q / (q.norm(p=2, dim=-1, keepdim=True) + self.eps)  # (B, T_q, D)\n",
        "        k_norm = k / (k.norm(p=2, dim=-1, keepdim=True) + self.eps)  # (B, T_k, D)\n",
        "        attention = torch.bmm(q_norm, k_norm.permute(0, 2, 1))  # (B, T_q, T_k)\n",
        "        if attn_mask is not None:\n",
        "            attention.masked_fill_(attn_mask, -np.inf)  # positions that require masking are now -np.inf\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        attention = self.dropout(attention)\n",
        "        output = attention.bmm(v)  # (B, T_q, D_v)\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "vThHga2PzBE2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slot Filling/Tagging model"
      ],
      "metadata": {
        "id": "-bODKt_5akn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from flair.data import Sentence\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, crf=True):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.crf = crf\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        \n",
        "        # self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "        #                     num_layers=3, bidirectional=True)\n",
        "        self.lstm = nn.GRU(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        \n",
        "        # self.attention = nn.Transformer(hidden_dim, nhead=10, num_encoder_layers=1).encoder\n",
        "        # self.attention_method = 'cosine'\n",
        "        # if self.attention_method != None:\n",
        "        #     self.linear_q = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        #     self.linear_k = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        #     self.linear_v = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "        # self.attention = CosineAttention()\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    # def init_hidden(self):\n",
        "    #     return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "    #             torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    def init_hidden(self):\n",
        "        return torch.randn(2, 1, self.hidden_dim // 2).to(device)\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # feats [L,9]\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # init_alphas [1,9]\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        # N: batch size\n",
        "        # L: sequence length\n",
        "        # D: 2 if bidirectional=True otherwise 1\n",
        "        # H_in: input size\n",
        "        # H_out: hidden size\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        # sentence = Sentence(\" \".join(sentence), use_tokenizer=False)\n",
        "        # embeds = self.word_embeds.embed(sentence)\n",
        "        # embeds = torch.stack([i.embedding for i in sentence])\n",
        "        # embeds = embeds.view(len(sentence), 1, -1).to(device)\n",
        "\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "\n",
        "        # sentence sentence torch.Size([8]), (L)\n",
        "        # embeds torch.Size([8, 1, 50]), (L,N,H_in)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        # lstm_out torch.Size([8, 1, 50]), (L,N,D*H_out)\n",
        "        # self.hidden[0] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "        # self.hidden[1] torch.Size([2, 1, 25]), (D*num_layers, N, H_out)\n",
        "\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        # lstm_out after view torch.Size([8, 50])\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        # lstm_feats torch.Size([8, 9])\n",
        "\n",
        "        # attention_out = self.attention(lstm_out)\n",
        "        # attention_out = attention_out.view(len(sentence), self.hidden_dim)\n",
        "        # lstm_feats = self.hidden2tag(attention_out)\n",
        "\n",
        "        # lstm_out = lstm_out.permute(1,0,2) \n",
        "        # q = self.linear_q(lstm_out)\n",
        "        # k = self.linear_k(lstm_out)\n",
        "        # v = self.linear_v(lstm_out)\n",
        "        # output, attention = self.attention(q,k,v)\n",
        "        # output = output.view(len(sentence), self.hidden_dim)\n",
        "        # attention_feats = self.hidden2tag(output)\n",
        "\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        # score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "\n",
        "        if self.crf:\n",
        "            # Find the best path, given the features.\n",
        "            score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        else:\n",
        "            tag_seq = torch.max(F.softmax(lstm_feats, dim=1), dim=1).indices.tolist()\n",
        "            score = None\n",
        "\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "Qoti5qtk9mTo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function for accuracy"
      ],
      "metadata": {
        "id": "g2-sKZd8FZDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy\n",
        "# def cal_acc(model, input_index, output_index):\n",
        "#     ground_truth = []\n",
        "#     predicted = []\n",
        "#     for i,idxs in enumerate(input_index):\n",
        "#         ground_truth += output_index[i]\n",
        "#         score, pred = model(idxs)\n",
        "#         predicted += pred\n",
        "#     accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "#     return predicted, ground_truth, accuracy"
      ],
      "metadata": {
        "id": "f91CWQAdFcyC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize model"
      ],
      "metadata": {
        "id": "QaPmSoqNEkIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 100\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "# HIDDEN_DIM = 818\n",
        "# EMBEDDING_DIM = 818\n",
        "# model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "d1AiIH0XEo47"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the model"
      ],
      "metadata": {
        "id": "Et311Pp2E3k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "# bptt = 100\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_val_input_index):\n",
        "    # for i, idxs in enumerate(train_data):\n",
        "        tags_index = train_val_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        # sentence_in = idxs\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    # # for i, idxs in enumerate(train_input_index):\n",
        "    # for i, idxs in enumerate(range(0,len(train_data)-1,bptt)):\n",
        "    #     seq_len = min(bptt, len(train_data) - idxs)\n",
        "    #     sentence_in = train_data[idxs: idxs+seq_len]\n",
        "    #     tags_index = train_output_index[idxs: idxs+seq_len]\n",
        "\n",
        "    #     # Step 1. Remember that Pytorch accumulates gradients.\n",
        "    #     # We need to clear them out before each instance\n",
        "    #     model.zero_grad()\n",
        "\n",
        "    #     # Step 2. Get our inputs ready for the network, that is,\n",
        "    #     # turn them into Tensors of word indices.\n",
        "\n",
        "    #     # sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "    #     targets = torch.tensor([tags_index], dtype=torch.long).to(device)\n",
        "\n",
        "    #     # Step 3. Run our forward pass.\n",
        "    #     loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "    #     # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "    #     # calling optimizer.step()\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "\n",
        "    #     train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "    # _, _, train_acc = cal_acc(model,train_data,train_output_index)\n",
        "    # _, _, val_acc = cal_acc(model,validation_data,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section\n",
        "# Please make sure you keep your own running log for submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwr4jcDiE57L",
        "outputId": "7bdc55f0-a277-4876-9044-8a7e0f3705dd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1, Training loss: 10681.41, train acc: 0.9947, val loss: 509.13, val acc: 0.9964, time: 1210.00s\n",
            "Epoch:2, Training loss: 2198.06, train acc: 0.9979, val loss: 195.85, val acc: 0.9992, time: 1192.55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, idxs in enumerate(range(0,511,100)):\n",
        "#   seq_len = min(100, 511 - 1 - idxs)\n",
        "#   print(i,idxs,seq_len,511 - 1 - idxs)\n",
        "#   print()"
      ],
      "metadata": {
        "id": "7i6fnK4zLbBM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "torch.save(model,'model')\n",
        "model = torch.load('model')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qstlc-K-I_i",
        "outputId": "4f5a0f5d-3e8c-45bb-fdda-e85844d1dfd1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF(\n",
              "  (word_embeds): Embedding(11243, 400)\n",
              "  (lstm): GRU(400, 50, bidirectional=True)\n",
              "  (hidden2tag): Linear(in_features=100, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "aqO86OgsGCpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "\n",
        "def test(model, input_index):\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    return predicted\n",
        "\n",
        "y_pred = test(model,test_input_index)\n",
        "\n",
        "# def test(model, input_index):\n",
        "#     predicted = []\n",
        "#     for i,idxs in enumerate(input_index):\n",
        "#         score, pred = model(test_data[i])\n",
        "#         predicted += pred\n",
        "#     return predicted\n",
        "\n",
        "# y_pred = test(model,test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "PENa3TFeGDgG"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_input_index)"
      ],
      "metadata": {
        "id": "WmsU96RoizE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0612db48-c8ab-4168-d188-8e4ede27b1d8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "metadata": {
        "id": "kSJ2kKNUf-hS"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in range(len(y_pred_decode)):\n",
        "  for token in y_pred_decode[i].split():\n",
        "    results.append(token)"
      ],
      "metadata": {
        "id": "MOSnBv8jjm49"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "id": "Zjvrw7dykoZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45ea733-2520-4a1e-e625-cc22cc123951"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2326"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.insert(0, 'Predicted')"
      ],
      "metadata": {
        "id": "jxMILiddlELJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "id": "12BfJTZYlXur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af96ca7f-9d1e-45f0-e045-6aa83fbe5a13"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2327"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id = [item for item in range(0, 2326)]"
      ],
      "metadata": {
        "id": "5PQNIdt3lZSR"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id.insert(0, 'Id')"
      ],
      "metadata": {
        "id": "7YmExrmul-_8"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "file = open(\"/content/gdrive/My Drive/COMP5046/2022-comp5046-a2/sample_200+200+fasttext+sgd+lr=0.01+crf+true.csv\", \"w\")\n",
        "writer = csv.writer(file)\n",
        "\n",
        "for w in range(len(results)):\n",
        "\n",
        "  writer.writerow([id[w], results[w]])\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "id": "R2C4YfSYmaQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daefc691-a8f1-4d7e-e970-77ca9c0994d7"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slot Filling/Tagging Model"
      ],
      "metadata": {
        "id": "5o8CKXGQz-y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline model"
      ],
      "metadata": {
        "id": "t2FGxs-t0Ex1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacked Seq2Seq model"
      ],
      "metadata": {
        "id": "Fk0S2FZw0LVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention"
      ],
      "metadata": {
        "id": "HO5P57L_0Oiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CRF Attachment"
      ],
      "metadata": {
        "id": "Wv4YNEetjcan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and Evaluation"
      ],
      "metadata": {
        "id": "o8-Be-Fqjgqy"
      }
    }
  ]
}