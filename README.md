# In-game Toxicity Detection
- Detected and classified inappropriate speech in more than 26k gaming conversations using machine learning
- Conducted data preprocessing with teammate using Python, spaCy and Gensim; implemented a Bi-GRU model to
detect in-game toxicity from dialogue texts
- Achieved accuracy of 97.25% with new model, ranking 3rd out of 312 participants in related Kaggle competition
- Generated a technical report analyzing strengths and weaknesses of new model, along with potential reasons
